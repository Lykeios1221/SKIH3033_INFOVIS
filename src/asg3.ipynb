{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import dtreeviz\n",
    "import ee\n",
    "import geemap\n",
    "import geojson\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy.interpolate\n",
    "import shap\n",
    "from cuml.explainer import PermutationExplainer\n",
    "from cuml.model_selection import train_test_split as cuml_train_test_split\n",
    "from optuna_integration import LightGBMPruningCallback\n",
    "from plotly import graph_objects as go\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.samplers import GPSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second enviroment import due to environment conflict between RAPIDSAI and Pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score,\n",
    "#     precision_recall_fscore_support,\n",
    "#     roc_auc_score,\n",
    "# )\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used:\n",
    "\n",
    "- [Global Flood Database v1 (2000-2018)](https://developers.google.com/earth-engine/datasets/catalog/GLOBAL_FLOOD_DB_MODIS_EVENTS_V1#description)\n",
    "\n",
    "- [USGS Landsat 7 Level 2, Collection 2, Tier 1 ](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LE07_C02_T2_L2#description)\n",
    "\n",
    "- [SRTM Digital Elevation Data Version 4 ](https://developers.google.com/earth-engine/datasets/catalog/CGIAR_SRTM90_V4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_collection: ee.ImageCollection = ee.ImageCollection(\n",
    "    \"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\"\n",
    ")\n",
    "\n",
    "landsat_collection: ee.ImageCollection = ee.ImageCollection(\n",
    "    \"LANDSAT/LE07/C02/T1_L2\"\n",
    ").filterDate(\"2000-02-17\", \"2018-12-10\")\n",
    "elevation_image = ee.Image(\"CGIAR/SRTM90_V4\")\n",
    "\n",
    "print(\"Image structure of each collection:\")\n",
    "display(flood_collection.first(), landsat_collection.first(), elevation_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the images with conditions:\n",
    "\n",
    "- Clear percentage of flood images **>= 0.5**\n",
    "\n",
    "- **Not** permanent water\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_flood(image):\n",
    "    clear_perc_mask = image.select(\"clear_perc\").gte(0.5)  # Clear percentage >= 50%\n",
    "    jrc_perm_water_mask = image.select(\"jrc_perm_water\").eq(\n",
    "        0\n",
    "    )  # 0 - non-water | 1 - permanent water\n",
    "\n",
    "    combined_mask = clear_perc_mask.And(jrc_perm_water_mask)\n",
    "\n",
    "    masked_image = image.updateMask(combined_mask)\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "flood_collection = flood_collection.map(mask_flood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose the following bands into an image collection:\n",
    "\n",
    "- **_x_**, **_y_**, _elevation_ as **_z_** and **_slope_**\n",
    "\n",
    "- **_SR_B1, SR_B2, SR_B3, SR_B4, SR_B5, SR_B7_** from Landsat Collection\n",
    "\n",
    "- **_NDWI_** calculated using SR_B2 and SR_B4\n",
    "\n",
    "- **_duration, clear_perc, flooded_** from Global Flood Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_interest_bands = [\"SR_B1\", \"SR_B2\", \"SR_B3\", \"SR_B4\", \"SR_B5\", \"SR_B7\"]\n",
    "flood_interest_bands = [\"duration\", \"clear_perc\", \"flooded\"]\n",
    "\n",
    "elevation = elevation_image.select(\"elevation\").rename(\"z\")\n",
    "slope = ee.Terrain.slope(elevation_image)\n",
    "\n",
    "\n",
    "def filter_single_scene(image):\n",
    "    date_range = ee.DateRange(\n",
    "        image.get(\"system:time_start\"), image.get(\"system:time_end\")\n",
    "    )\n",
    "    return ee.Algorithms.If(\n",
    "        date_range.end().difference(date_range.start(), \"days\").gt(0), image, None\n",
    "    )\n",
    "\n",
    "\n",
    "def compose_landsat(image):\n",
    "    geometry = image.geometry()\n",
    "    date_range = ee.DateRange(\n",
    "        image.get(\"system:time_start\"), image.get(\"system:time_end\")\n",
    "    )\n",
    "    landsat_image = (\n",
    "        landsat_collection.select(ee.List(landsat_interest_bands))\n",
    "        .filterDate(date_range.start(), date_range.end())\n",
    "        .filterBounds(geometry)\n",
    "        .median()\n",
    "    )\n",
    "    return ee.Algorithms.If(\n",
    "        landsat_image.bandNames().length(),\n",
    "        image.select(flood_interest_bands).addBands(\n",
    "            landsat_image,\n",
    "            ee.List(landsat_interest_bands),\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "\n",
    "def add_elevation_bands(image: ee.Image):\n",
    "    return image.addBands(elevation).addBands(slope)\n",
    "\n",
    "\n",
    "def set_default_projection(image: ee.Image):\n",
    "    projection = image.select(\"flooded\").projection()\n",
    "    return image.setDefaultProjection(projection)\n",
    "\n",
    "\n",
    "images = (\n",
    "    flood_collection.map(filter_single_scene, True)\n",
    "    .map(compose_landsat, True)\n",
    "    .map(add_elevation_bands)\n",
    "    .map(set_default_projection)\n",
    ")\n",
    "print(f\"Number of flood event images left: {images.size().getInfo()}\")\n",
    "images.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(image: ee.Image):\n",
    "    # Reduce resolution of bands to a common scale\n",
    "    image = image.addBands(\n",
    "        image.select([*landsat_interest_bands, \"z\", \"slope\"]).reduceResolution(\n",
    "            reducer=ee.Reducer.mean()\n",
    "        ),\n",
    "        overwrite=True,\n",
    "    )\n",
    "    return image.stratifiedSample(\n",
    "        classBand=\"flooded\",\n",
    "        numPoints=50,\n",
    "        dropNulls=True,\n",
    "        scale=250,\n",
    "        tileScale=4,\n",
    "        region=image.geometry(),\n",
    "        geometries=False,\n",
    "        projection=image.projection(),\n",
    "    )\n",
    "\n",
    "\n",
    "dataset = images.map(to_features).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geemap.ee_export_vector_to_drive(dataset, description=\"flood_dataset\", fileFormat=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the details of flood events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_properties = {\n",
    "    \"system:index\": \"id\",\n",
    "    \"dfo_country\": \"primary_country\",\n",
    "    \"dfo_severity\": \"severity\",\n",
    "    \"system:time_start\": \"start_date\",\n",
    "    \"system:time_end\": \"end_date\",\n",
    "    \"dfo_centroid_x\": \"center_lon\",\n",
    "    \"dfo_centroid_y\": \"center_lat\",\n",
    "    \"dfo_main_cause\": \"main_cause\",\n",
    "    \"dfo_dead\": \"dead\",\n",
    "    \"dfo_displaced\": \"displaced\",\n",
    "}\n",
    "\n",
    "\n",
    "def extract_properties(image):\n",
    "    old_keys = ee.List(list(interest_properties.keys()))\n",
    "    new_keys = ee.List(list(interest_properties.values()))\n",
    "    props: ee.Dictionary = image.toDictionary(old_keys).rename(old_keys, new_keys, True)\n",
    "    mask = image.select(\"flooded\").gt(0)\n",
    "    area = (\n",
    "        ee.Image.pixelArea()\n",
    "        .mask(mask)\n",
    "        .reduceRegion(\n",
    "            reducer=ee.Reducer.sum(),\n",
    "            scale=250,\n",
    "            geometry=image.geometry(),\n",
    "            maxPixels=412598311,\n",
    "            crs=image.projection(),\n",
    "        )\n",
    "    ).get(\"area\")\n",
    "    props = props.set(\"area\", area)\n",
    "    return ee.Feature(None, props)\n",
    "\n",
    "\n",
    "flood_properties = ee.FeatureCollection(flood_collection.map(extract_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geemap.ee_to_csv(flood_properties, filename=\"../data/asg3/flood_props.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for data distribution and null entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood_props = pd.read_csv(\"../data/asg3/flood_props.csv\", index_col=\"id\").reset_index()\n",
    "display(df_flood_props.head(), df_flood_props.describe(), df_flood_props.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood_data = pd.read_csv(\"../data/asg3/flood_dataset.csv\", index_col=\"system:index\").reset_index()\n",
    "display(df_flood_data.head(), df_flood_data.describe(), df_flood_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood_data = pd.read_csv(\"../data/asg3/flood_dataset.csv\", index_col=\"system:index\").reset_index()\n",
    "display(df_flood_data.head(), df_flood_data.describe(), df_flood_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"countries.geojson\") as f:\n",
    "    countries_boundary = geojson.load(f)\n",
    "\n",
    "countries_ADM = [\n",
    "    feature[\"properties\"][\"ADMIN\"] for feature in countries_boundary[\"features\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify all country is valid with ADM standard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_country_exists_ADM(countries):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"primary_country\": countries,\n",
    "            \"exists_in_ADM\": countries.isin(countries_ADM),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "df_temp = check_country_exists_ADM(\n",
    "    pd.Series(df_flood_props[\"primary_country\"].unique())\n",
    ")\n",
    "df_temp[df_temp[\"exists_in_ADM\"] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform invalid countries' value according to ADM standard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_adm = {\n",
    "    \"USA\": \"United States of America\",\n",
    "    \"UK\": \"United Kingdom\",\n",
    "    \"Burma\": \"Myanmar\",\n",
    "    \"Tanzania\": \"United Republic of Tanzania\",\n",
    "    \"Columbia\": \"Colombia\",\n",
    "    \"Bosnia-Herzegovina\": \"Bosnia and Herzegovina\",\n",
    "    \"Guatamala\": \"Guatemala\",\n",
    "    \"Serbia\": \"Republic of Serbia\",\n",
    "    \"Africa\": \"Central African Republic\",  # Africa is a continent, not a country\n",
    "    \"Texas\": \"United States of America\",  # Texas is a state in the USA\n",
    "    \"Venezulea\": \"Venezuela\",\n",
    "    \"Serbia-Montenegro\": \"Republic of Serbia\",  # No longer exists as a single country\n",
    "    \"Inda\": \"India\",\n",
    "    \"Democratic Republic of Congo\": \"Democratic Republic of the Congo\",\n",
    "    \"Tasmania\": \"Australia\",  # Tasmania is a state in Australia\n",
    "    \"The Gambia\": \"Gambia\",\n",
    "    \"Scotland\": \"United Kingdom\",  # Scotland is part of the United Kingdom\n",
    "    \"Gaza\": \"Palestine\",  # Gaza is a region in Palestine\n",
    "    \"Kazahkstan\": \"Kazakhstan\",\n",
    "    \"Uruguay,\": \"Uruguay\",\n",
    "    \"Bahamas\": \"The Bahamas\",\n",
    "}\n",
    "\n",
    "\n",
    "def process_country_name(country):\n",
    "    processed_country = country_to_adm.get(country)\n",
    "    return processed_country if processed_country else country\n",
    "\n",
    "\n",
    "df_flood_props_cleaned = df_flood_props.copy()\n",
    "df_flood_props_cleaned[\"primary_country\"] = df_flood_props[\"primary_country\"].apply(\n",
    "    process_country_name\n",
    ")\n",
    "df_temp = check_country_exists_ADM(\n",
    "    pd.Series(df_flood_props_cleaned[\"primary_country\"].unique())\n",
    ")\n",
    "df_temp.sort_values(\"exists_in_ADM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flood_props_cleaned.to_csv(\"../data/asg3/flood_props_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causes = [x.lower() for x in df_flood_props_cleaned[\"main_cause\"].to_list()]\n",
    "\n",
    "categories = {\n",
    "    \"Heavy rain\": [\"rain\", \"monsoon\", \"torrential\"],\n",
    "    \"Dam break/release\": [\"dam\", \"levy\", \"release\"],\n",
    "    \"Snowmelt\": [\"snow\"],\n",
    "    \"Ice jam\": [\"ice\"],\n",
    "    \"Tropical storm\": [\"tropical\", \"typhoon\", \"hurricane\"],\n",
    "}\n",
    "\n",
    "df_flood_cause = pd.DataFrame(\n",
    "    data={\n",
    "        \"event\": list(categories.keys()) + [\"Other\"],\n",
    "        \"count\": np.zeros(len(categories) + 1, dtype=int),\n",
    "        \"matched\": [[] for _ in range(len(categories) + 1)],\n",
    "    }\n",
    ")\n",
    "\n",
    "for event in causes:\n",
    "    matched = False\n",
    "    for category, keywords in categories.items():\n",
    "        if any(keyword in event for keyword in keywords):\n",
    "            idx = df_flood_cause.index[df_flood_cause[\"event\"] == category].tolist()[0]\n",
    "            df_flood_cause.at[idx, \"count\"] += 1\n",
    "            df_flood_cause.at[idx, \"matched\"].append(event)\n",
    "            matched = True\n",
    "    if not matched:\n",
    "        idx = df_flood_cause.index[df_flood_cause[\"event\"] == \"Other\"].tolist()[0]\n",
    "        df_flood_cause.at[idx, \"count\"] += 1\n",
    "        df_flood_cause.at[idx, \"matched\"].append(event)\n",
    "\n",
    "\n",
    "fig = px.bar(\n",
    "    df_flood_cause,\n",
    "    x=\"event\",\n",
    "    y=\"count\",\n",
    "    color=\"count\",\n",
    "    text=\"count\",\n",
    ")\n",
    "fig.update_layout(title=dict(text=\"Main Cause of Flood Events\", x=0.5))\n",
    "fig.show()\n",
    "fig = px.pie(\n",
    "    df_flood_data[\"flooded\"].value_counts().to_frame().reset_index(),\n",
    "    values=\"count\",\n",
    "    names=[\"Non-water\", \"Flooded\"],\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Ratio of Flooded Area Against Non-Water Area in Dataset\", x=0.5),\n",
    "    margin_b=20,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global flood occurrence (only primary influenced country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flood_by_country = pd.DataFrame(\n",
    "    df_flood_props_cleaned[\"primary_country\"].value_counts().reset_index(name=\"counts\")\n",
    ")\n",
    "\n",
    "scattergeo_trace = go.Scattergeo(\n",
    "    lat=df_flood_props_cleaned[\"center_lat\"],\n",
    "    lon=df_flood_props_cleaned[\"center_lon\"],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        opacity=0.8,\n",
    "        autocolorscale=False,\n",
    "        symbol=\"triangle-down\",\n",
    "        colorscale=\"Reds\",\n",
    "        cmin=0,\n",
    "        color=df_flood_props_cleaned[\"severity\"],\n",
    "        cmax=df_flood_props_cleaned[\"severity\"].max(),\n",
    "        colorbar_title=\"Severity\",\n",
    "        colorbar_x=1.15,\n",
    "    ),\n",
    "    hoverinfo=\"skip\",\n",
    ")\n",
    "\n",
    "choropleth_trace = go.Choropleth(\n",
    "    locations=df_flood_by_country[\"primary_country\"],\n",
    "    locationmode=\"country names\",\n",
    "    z=df_flood_by_country[\"counts\"],\n",
    "    colorscale=\"amp\",\n",
    "    colorbar_title=\"Occurence\",\n",
    "    hoverlabel_namelength=0,\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[scattergeo_trace, choropleth_trace])\n",
    "fig.data[0].showlegend = False\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Flood Severity and Occurrence\",\n",
    "    title_x=0.5,\n",
    "    geo=dict(\n",
    "        showland=True,\n",
    "        landcolor=\"rgb(95, 138, 92)\",\n",
    "        showcountries=True,\n",
    "        countrycolor=\"rgb(255, 255, 255)\",\n",
    "        showocean=True,\n",
    "        oceancolor=\"rgb(158,202,225)\",\n",
    "        projection_type=\"orthographic\",\n",
    "    ),\n",
    "    margin={\"b\": 15, \"l\": 20, \"r\": 0, \"t\": 70},\n",
    "    shapes=list(\n",
    "        [\n",
    "            dict(\n",
    "                fillcolor=\"rgb(95, 138, 92)\",\n",
    "                layer=\"below\",\n",
    "                line={\"dash\": \"dash\"},\n",
    "                name=\"Country not primarily <br>affected by flood\",\n",
    "                showlegend=True,\n",
    "                type=\"rect\",\n",
    "                xref=\"paper\",\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        bgcolor=\"LightSteelBlue\",\n",
    "        bordercolor=\"Black\",\n",
    "        borderwidth=1,\n",
    "    ),\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": [\n",
    "                {\n",
    "                    \"args\": [\n",
    "                        {\"geo.projection.type\": \"orthographic\"},\n",
    "                    ],\n",
    "                    \"label\": \"Orthographic\",\n",
    "                    \"method\": \"relayout\",\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [\n",
    "                        {\"geo.projection.type\": \"equirectangular\"},\n",
    "                    ],\n",
    "                    \"label\": \"Equirectangular\",\n",
    "                    \"method\": \"relayout\",\n",
    "                },\n",
    "            ],\n",
    "            \"direction\": \"left\",\n",
    "            \"showactive\": True,\n",
    "            \"type\": \"buttons\",\n",
    "            \"x\": 0,\n",
    "            \"xanchor\": \"left\",\n",
    "            \"y\": 1.15,\n",
    "            \"yanchor\": \"top\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_flood_props_cleaned,\n",
    "    x=\"displaced\",\n",
    "    y=\"dead\",\n",
    "    size=\"area\",\n",
    "    color=\"primary_country\",\n",
    "    hover_name=\"id\",\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Estimated Displaced Against Fatalities Due to Flood Event\", x=0.5),\n",
    "    height=750,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the image of 2010 Pakistan floods for visualizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_flood = \"DFO_2507_From_20040620_to_20041007\"\n",
    "max_pixels = 10000\n",
    "scale = 25000\n",
    "\n",
    "target_image = (\n",
    "    images.filter(ee.Filter.eq(\"system:index\", target_flood)).first().unmask()\n",
    ")\n",
    "\n",
    "# Extract the image as features (x, y, z, flooded) to investigate the relationship between elevation/slope and flood\n",
    "target_image_features = ee.FeatureCollection(\n",
    "    target_image.reduceResolution(reducer=ee.Reducer.mean(), maxPixels=max_pixels)\n",
    "    .addBands(ee.Image.pixelCoordinates(projection=target_image.projection()))\n",
    "    .select([\"x\", \"y\", \"z\", \"flooded\"])\n",
    "    .reduceRegion(\n",
    "        ee.Reducer.toCollection([\"x\", \"y\", \"z\", \"flooded\"]),\n",
    "        scale=scale,\n",
    "        geometry=target_image.geometry().bounds(),\n",
    "        crs=target_image.projection(),\n",
    "    )\n",
    "    .get(\"features\")\n",
    ")\n",
    "\n",
    "display(target_image)\n",
    "print(f\"Number of points: {target_image_features.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geemap.ee_to_csv(\n",
    "#     target_image_features, filename=f\"../data/asg3/{target_flood}_data.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 3D DEM of target image with flood area colored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_data = pd.read_csv(f\"../data/asg3/{target_flood}_data.csv\").to_numpy()\n",
    "\n",
    "flooded = target_image_data[:, 0]\n",
    "x = target_image_data[:, 1]\n",
    "y = target_image_data[:, 2]\n",
    "z = target_image_data[:, -1]\n",
    "\n",
    "xmin, xmax = np.min(x), np.max(x)\n",
    "ymin, ymax = np.min(y), np.max(y)\n",
    "xstep, ystep = (\n",
    "    np.round((xmax - xmin) / np.unique(x).shape).item(),\n",
    "    np.round((ymax - ymin) / np.unique(y).shape).item(),\n",
    ")\n",
    "u = np.arange(start=xmin, stop=xmax, step=xstep)\n",
    "v = np.arange(start=ymin, stop=ymax, step=ystep)\n",
    "\n",
    "X, Y = np.meshgrid(u, v)\n",
    "Z = scipy.interpolate.griddata(\n",
    "    (x, y), z, (X, Y), method=\"nearest\", fill_value=0, rescale=True\n",
    ")\n",
    "F = scipy.interpolate.griddata(\n",
    "    (x, y), flooded, (X, Y), method=\"nearest\", fill_value=0, rescale=True\n",
    ")\n",
    "Fmin, Fmax = np.min(F), np.max(F)\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Surface(\n",
    "            z=Z, colorscale=\"Plotly3\", showscale=True, colorbar_title=\"Elevation\"\n",
    "        ),\n",
    "        go.Surface(\n",
    "            z=Z + 150,\n",
    "            surfacecolor=F,\n",
    "            cmin=Fmin,\n",
    "            cmax=Fmax,\n",
    "            colorscale=[\n",
    "                [0, \"rgba(7, 148, 242, 0.0)\"],\n",
    "                [0.3, \"rgba(7, 148, 242, 1.0)\"],\n",
    "                [1, \"rgba(7, 148, 242, 1.0)\"],\n",
    "            ],\n",
    "            colorbar=dict(title=\"Flood mean\", x=-0.1),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "fig.update_traces(\n",
    "    contours_z=dict(\n",
    "        show=True,\n",
    "        usecolormap=True,\n",
    "        project_z=True,\n",
    "        color=\"rgba(255, 0, 0, 0.5)\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    scene_camera_eye=dict(x=1.5, y=1.5, z=1.25),\n",
    "    margin=dict(l=0, r=0, t=0, b=30),\n",
    "    title=dict(text=f\"3D DEM of {target_flood}\", x=0.5, y=0.95),\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Toggle Elevation Surface\",\n",
    "                    method=\"update\",\n",
    "                    args=[\n",
    "                        {\n",
    "                            \"visible\": [True, True],\n",
    "                            \"contours.z.usecolormap\": [True, True],\n",
    "                        },\n",
    "                    ],\n",
    "                    args2=[\n",
    "                        {\n",
    "                            \"visible\": [False, True],\n",
    "                            \"contours.z.usecolormap\": [False, False],\n",
    "                        },\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "            direction=\"left\",\n",
    "            showactive=True,\n",
    "            x=-0.1,\n",
    "            xanchor=\"left\",\n",
    "            y=1.1,\n",
    "            yanchor=\"top\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize dataset and target flood event with satellite view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "Map.add_basemap(\"HYBRID\")\n",
    "\n",
    "vis_params = {\"min\": 0, \"max\": 10, \"palette\": [\"c3effe\", \"1341e8\", \"051cb0\", \"001133\"]}\n",
    "\n",
    "Map.addLayer(\n",
    "    flood_collection.select(\"jrc_perm_water\").sum().gte(1).selfMask(),\n",
    "    {\"min\": 0, \"max\": 1, \"palette\": \"c3effe\"},\n",
    "    \"JRC Permanent Water\",\n",
    ")\n",
    "\n",
    "Map.addLayer(\n",
    "    flood_collection.select(\"flooded\").sum().selfMask(),\n",
    "    vis_params,\n",
    "    \"GFD Satellite Observed Flood Plain\",\n",
    ")\n",
    "\n",
    "Map.add_colorbar_branca(\n",
    "    colors=vis_params[\"palette\"],\n",
    "    vmin=vis_params[\"min\"],\n",
    "    vmax=vis_params[\"max\"],\n",
    "    layer_name=\"\",\n",
    "    caption=\"Flood occurrence\",\n",
    "    discrete=True,\n",
    ")\n",
    "\n",
    "Map.addLayer(\n",
    "    images.select(\"flooded\").sum().selfMask(),\n",
    "    vis_params,\n",
    "    \"Masked GFD Satellite Observed Flood Plain\",\n",
    ")\n",
    "\n",
    "Map.addLayer(\n",
    "    target_image.select(\"flooded\").selfMask(),\n",
    "    vis_params,\n",
    "    \"Selected flood event\",\n",
    ")\n",
    "Map.addLayer(\n",
    "    ee.FeatureCollection(ee.Feature(target_image.geometry().bounds())).style(\n",
    "        color=\"red\", fillColor=\"00000000\"\n",
    "    ),\n",
    "    {},\n",
    "    \"Selected flood event boundary\",\n",
    ")\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial selected features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"SR_B1\": \"Blue\",\n",
    "    \"SR_B2\": \"Green\",\n",
    "    \"SR_B3\": \"Red\",\n",
    "    \"SR_B4\": \"NIR\",\n",
    "    \"SR_B5\": \"SWIR_1\",\n",
    "    \"SR_B7\": \"SWIR_2\",\n",
    "    \"slope\": \"Slope\",\n",
    "    \"z\": \"Elevation\",\n",
    "}\n",
    "x = df_flood_data[features.keys()].rename(columns=features)\n",
    "y = df_flood_data[\"flooded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Band Performance Comparison\n",
    "\n",
    "- https://www.researchgate.net/publication/328853274_Remote_sensing_gis_and_hec-ras_techniques_applied_for_flood_extent_validation_based_on_landsat_imagery_lidar_and_hydrological_data_Case_study_Baseu_river_Romania\n",
    "- https://www.sciencedirect.com/science/article/pii/S1110982321000703\n",
    "\n",
    "MBI\n",
    "\n",
    "- https://www.mdpi.com/2073-445X/10/3/231\n",
    "- https://www.sciencedirect.com/science/article/pii/S2772375524000340\n",
    "\n",
    "Transformed Index\n",
    "\n",
    "- NDWI - Normalized Difference Water Index\n",
    "- MBI - Modified Bare Soil Index\n",
    "- NDVI - Normalized Difference Vegetation Index\n",
    "- WRI - Water Ratio Index\n",
    "- AWEI - Automated Water Extraction Index\n",
    "- SI - Surface Index\n",
    "- NWI - New Water Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"NDWI\"] = (x[\"Green\"] - x[\"NIR\"]) / (x[\"Green\"] + x[\"NIR\"])\n",
    "x[\"MBI\"] = (\n",
    "    (x[\"SWIR_1\"] - x[\"SWIR_2\"] - x[\"NIR\"]) / (x[\"SWIR_1\"] + x[\"SWIR_2\"] + x[\"NIR\"])\n",
    ") + 0.5\n",
    "x[\"NDVI\"] = (x[\"NIR\"] - x[\"Red\"]) / (x[\"NIR\"] + x[\"Red\"])\n",
    "x[\"WRI\"] = (x[\"Green\"] + x[\"Red\"]) / (x[\"NIR\"] + x[\"SWIR_2\"])\n",
    "x[\"AWEI\"] = (\n",
    "    x[\"Blue\"] + 2.5 * x[\"Green\"] - 1.5 * (x[\"NIR\"] + x[\"SWIR_1\"]) - 0.25 * x[\"SWIR_2\"]\n",
    ")\n",
    "x[\"SI\"] = (1 - x[\"Red\"]) * (1 - x[\"Blue\"]) * (1 - x[\"Green\"])\n",
    "x[\"NWI\"] = (x[\"Blue\"] - (x[\"NIR\"] + x[\"SWIR_1\"] + x[\"SWIR_2\"])) / (\n",
    "    x[\"Blue\"] + (x[\"NIR\"] + x[\"SWIR_1\"] + x[\"SWIR_2\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation heatmap of initial selected features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x.corr().round(4)\n",
    "fig = px.imshow(corr, text_auto=True, aspect=\"auto\")\n",
    "fig.update_layout(title=dict(text=\"Correlation of Features\", x=0.5))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LightGBM as base model for SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    deterministic=True,\n",
    "    device_type=\"cpu\",\n",
    "    verbose=0,\n",
    ")\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cuml_train_test_split(\n",
    "    x, y, test_size=0.3, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "forest.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "full_clustering_path = Path(\"../data/asg3/f_clustering.npy\")\n",
    "shap_values_path = Path(\"../data/asg3/shap_values.npy\")\n",
    "\n",
    "if full_clustering_path.exists():\n",
    "    clustering = np.load(full_clustering_path)\n",
    "else:\n",
    "    clustering = shap.utils.hclust(X_train.to_numpy(), y_train.to_numpy())\n",
    "    np.save(full_clustering_path, clustering)\n",
    "\n",
    "if shap_values_path.exists():\n",
    "    shap_values = np.load(shap_values_path)\n",
    "else:\n",
    "    masker = shap.maskers.Partition(X_train.to_numpy(), clustering=clustering)\n",
    "    explainer = PermutationExplainer(\n",
    "        forest.predict_proba, masker, data=X_train, masker_type=\"partition\"\n",
    "    )\n",
    "    shap_values = explainer.shap_values(X_test.to_numpy())\n",
    "    np.save(shap_values_path, shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_value = np.mean(forest.predict_proba(X_test.to_numpy()), axis=0)\n",
    "\n",
    "explanation = shap.Explanation(\n",
    "    shap_values,\n",
    "    data=X_test.to_numpy(),\n",
    "    base_values=np.full(shape=np.sum(shap_values, axis=1).shape, fill_value=expected_value),\n",
    "    feature_names=list(x.columns.values),\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "\n",
    "axes[0].set_title(\"Feature Importance and Clustering \\nBased on SHAP Values\")\n",
    "shap.plots.bar(explanation[...,1], clustering=clustering, max_display=len(x.columns), ax=axes[0], show=False)\n",
    "\n",
    "shap.decision_plot(expected_value[1], shap_values[...,1][:10], feature_names=list(x.columns.values), show=False)\n",
    "axes[1] = plt.gca()\n",
    "axes[1].set_title(\"Complexity of Model for Making Prediction\")\n",
    "fig.set_dpi(1000)\n",
    "fig.suptitle(\"Analysis for All Features\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches((10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_features = [\"AWEI\", \"NIR\", \"Slope\", \"Elevation\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    x[final_features], y, test_size=0.3, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=(1 / 3), stratify=y_temp\n",
    ")\n",
    "\n",
    "np.savez(\n",
    "    \"../data/asg3/complete_data.npz\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load(\"../data/asg3/complete_data.npz\")\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    X_val,\n",
    "    y_val,\n",
    ") = (\n",
    "    data[\"X_train\"],\n",
    "    data[\"X_test\"],\n",
    "    data[\"y_train\"],\n",
    "    data[\"y_test\"],\n",
    "    data[\"X_val\"],\n",
    "    data[\"y_val\"],\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(X_train, y_train, params={\"feature_pre_filter\": False})\n",
    "\n",
    "X_val_early_stop, X_val_tune, y_val_early_stop, y_val_tune = train_test_split(\n",
    "    X_val, y_val, test_size=0.5, shuffle=True, stratify=y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.GPUTreeExplainer(forest)\n",
    "clustering = shap.utils.hclust(X_train, y_train)\n",
    "\n",
    "explanation = explainer(X_test)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 8))\n",
    "\n",
    "axes[0].set_title(\"Feature Importance and Clustering \\nBased on SHAP Values\")\n",
    "shap.plots.bar(\n",
    "    explanation,\n",
    "    clustering=clustering,\n",
    "    max_display=len(x.columns),\n",
    "    ax=axes[0],\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "shap.decision_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values[:10],\n",
    "    feature_names=final_features,\n",
    "    link=\"logit\",\n",
    "    show=False,\n",
    "    auto_size_plot=False,\n",
    ")\n",
    "axes[1] = plt.gca()\n",
    "axes[1].set_title(\"Complexity of Model for Making Prediction\")\n",
    "fig.set_dpi(1000)\n",
    "fig.suptitle(\"Analysis for Selected Features\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches((10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(y_pred, y_test):\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"binary\"\n",
    "    )\n",
    "    accuracy = accuracy_score(y_test, lgb_y_pred)\n",
    "    auc = roc_auc_score(y_test, lgb_y_pred)\n",
    "    return [accuracy, precision, recall, f1, auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logistic_model \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m()\n\u001b[1;32m      2\u001b[0m logistic_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      4\u001b[0m lr_y_pred \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "lr_y_pred = logistic_model.predict(X_test)\n",
    "lr_results = evaluate_model(lr_y_pred, y_test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb_model = lgb.cv(\n",
    "    {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"device_type\": \"cpu\",\n",
    "        \"verbose\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"deterministic\": True,\n",
    "    },\n",
    "    train_data,\n",
    "    nfold=5,\n",
    "    stratified=True,\n",
    "    shuffle=True,\n",
    "    metrics=\"auc\",\n",
    "    return_cvbooster=True,\n",
    ")\n",
    "# Predict and evaluate\n",
    "lgb_y_pred = (lgb_model[\"cvbooster\"].predict(X_test)[0] > 0.5).astype(\"int\")\n",
    "lgb_results = evaluate_model(lgb_y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tabnet = TabNetClassifier(device_name=\"cuda\", verbose=0)\n",
    "tabnet.fit(X_train, y_train, eval_set=[(X_val_early_stop, y_val_early_stop)])\n",
    "\n",
    "tabnet_y_pred = tabnet.predict(X_test)\n",
    "tabnet_results = evaluate_model(tabnet_y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\"],\n",
    "        \"Logistic Regression\": lr_results,\n",
    "        \"LightGBM\": lgb_results,\n",
    "        \"TabNet\": tabnet_results,\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics_df.to_csv(\"../data/asg3/initial_results.csv\", index=False)\n",
    "metrics_df.style.background_gradient(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21685/3556903182.py:43: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "[I 2024-08-01 05:10:13,274] Using an existing study with name 'LightGBM_study' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"device_type\": \"cpu\",\n",
    "        \"verbose\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"deterministic\": True,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 0, 15),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 1024),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n",
    "        \"num_iterations\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-6, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-6, 10.0, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 20, 800),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    }\n",
    "\n",
    "    # Create the LightGBM model\n",
    "    model = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        nfold=5,\n",
    "        stratified=True,\n",
    "        shuffle=True,\n",
    "        metrics=\"auc\",\n",
    "        return_cvbooster=True,\n",
    "    )\n",
    "\n",
    "    y_pred = (model[\"cvbooster\"].predict(X_test)[0] > 0.5).astype(\"int\")\n",
    "    auc = roc_auc_score(y_val_tune, y_pred)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"LightGBM_study\",\n",
    "    storage=\"sqlite:///../data/asg3/lightgbm_optuna.db\",\n",
    "    load_if_exists=True,\n",
    "    sampler=GPSampler(seed=0, deterministic_objective=True),\n",
    "    pruner=optuna.pruners.SuccessiveHalvingPruner(),\n",
    ")\n",
    "\n",
    "n_trials = 3000\n",
    "\n",
    "\n",
    "def ensure_n_trials(study, trial):\n",
    "    if trial.number >= n_trials:\n",
    "        study.stop()\n",
    "\n",
    "\n",
    "study.optimize(objective, n_trials=n_trials, callbacks=[ensure_n_trials], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration.lightgbm import LightGBMTunerCV\n",
    "\n",
    "cv_study = optuna.create_study(\n",
    "    study_name=\"LightGBM_tuner_cv\",\n",
    "    storage=\"sqlite:///../data/asg3/lightgbm_tuner_cv.db\",\n",
    ")\n",
    "\n",
    "tuner = LightGBMTunerCV(\n",
    "    {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"device_type\": \"cpu\",\n",
    "        \"verbose\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"deterministic\": True,\n",
    "    },\n",
    "    train_data,\n",
    "    verbose_eval=False,\n",
    "    study=cv_study,\n",
    "    nfold=5,\n",
    "    stratified=True,\n",
    "    shuffle=True,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "tuner.set_verbosity(-1)\n",
    "\n",
    "tuner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 559\n",
      "Value: 0.929425377499083\n",
      "Params: \n",
      "    max_depth: 15\n",
      "    num_leaves: 283\n",
      "    learning_rate: 0.084350629755705\n",
      "    n_estimators: 723\n",
      "    lambda_l1: 1.1690787181558855\n",
      "    lambda_l2: 0.9437281129035027\n",
      "    feature_fraction: 0.8530414503922408\n",
      "    min_child_samples: 181\n",
      "    bagging_fraction: 0.7963514731926218\n",
      "    bagging_freq: 6\n"
     ]
    }
   ],
   "source": [
    "best_trial = study.trials_dataframe()[\"value\"].idxmax()\n",
    "trials = study.get_trials()\n",
    "\n",
    "print(f\"Best trial: {best_trial}\")\n",
    "print(f\"Value: {trials[best_trial].value}\")\n",
    "print(\"Params: \")\n",
    "for key, value in trials[best_trial].params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = trials[best_trial].params\n",
    "tuned_lgb = lgb.train(\n",
    "    {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"device_type\": \"cpu\",\n",
    "        \"verbose\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"deterministic\": True,\n",
    "        **best_params,\n",
    "    },\n",
    "    train_data,\n",
    "    valid_sets=[val_data_early_stop],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "tuned_lgb_y_pred = (tuned_lgb.predict(X_test) > 0.5).astype(\"int\")\n",
    "tuned_lgb_precision, tuned_lgb_recall, tuned_lgb_f1, tuned_lgb_support = (\n",
    "    precision_recall_fscore_support(y_test, tuned_lgb_y_pred, average=\"binary\")\n",
    ")\n",
    "tuned_lgb_accuracy = accuracy_score(y_test, tuned_lgb_y_pred)\n",
    "tuned_lgb_auc = roc_auc_score(y_test, tuned_lgb_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_035b8_row0_col1, #T_035b8_row0_col4, #T_035b8_row0_col5 {\n",
       "  background-color: #023e62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_035b8_row0_col2 {\n",
       "  background-color: #2182b9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_035b8_row0_col3 {\n",
       "  background-color: #023c5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_035b8_row1_col1, #T_035b8_row1_col2, #T_035b8_row1_col4, #T_035b8_row1_col5, #T_035b8_row3_col3 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_035b8_row1_col3 {\n",
       "  background-color: #d1d2e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_035b8_row2_col1, #T_035b8_row2_col3, #T_035b8_row2_col4, #T_035b8_row2_col5, #T_035b8_row3_col2 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_035b8_row2_col2 {\n",
       "  background-color: #1b7eb7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_035b8_row3_col1 {\n",
       "  background-color: #0568a3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_035b8_row3_col4 {\n",
       "  background-color: #328dbf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_035b8_row3_col5 {\n",
       "  background-color: #0569a5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_035b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_035b8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_035b8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_035b8_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_035b8_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_035b8_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
       "      <th id=\"T_035b8_level0_col5\" class=\"col_heading level0 col5\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_035b8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_035b8_row0_col0\" class=\"data row0 col0\" >Tuned_LightGBM</td>\n",
       "      <td id=\"T_035b8_row0_col1\" class=\"data row0 col1\" >0.855401</td>\n",
       "      <td id=\"T_035b8_row0_col2\" class=\"data row0 col2\" >0.876519</td>\n",
       "      <td id=\"T_035b8_row0_col3\" class=\"data row0 col3\" >0.823401</td>\n",
       "      <td id=\"T_035b8_row0_col4\" class=\"data row0 col4\" >0.849130</td>\n",
       "      <td id=\"T_035b8_row0_col5\" class=\"data row0 col5\" >0.855033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_035b8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_035b8_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_035b8_row1_col1\" class=\"data row1 col1\" >0.791521</td>\n",
       "      <td id=\"T_035b8_row1_col2\" class=\"data row1 col2\" >0.799062</td>\n",
       "      <td id=\"T_035b8_row1_col3\" class=\"data row1 col3\" >0.772369</td>\n",
       "      <td id=\"T_035b8_row1_col4\" class=\"data row1 col4\" >0.785489</td>\n",
       "      <td id=\"T_035b8_row1_col5\" class=\"data row1 col5\" >0.791302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_035b8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_035b8_row2_col0\" class=\"data row2 col0\" >LightGBM</td>\n",
       "      <td id=\"T_035b8_row2_col1\" class=\"data row2 col1\" >0.856977</td>\n",
       "      <td id=\"T_035b8_row2_col2\" class=\"data row2 col2\" >0.878555</td>\n",
       "      <td id=\"T_035b8_row2_col3\" class=\"data row2 col3\" >0.824576</td>\n",
       "      <td id=\"T_035b8_row2_col4\" class=\"data row2 col4\" >0.850710</td>\n",
       "      <td id=\"T_035b8_row2_col5\" class=\"data row2 col5\" >0.856605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_035b8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_035b8_row3_col0\" class=\"data row3 col0\" >TabNet</td>\n",
       "      <td id=\"T_035b8_row3_col1\" class=\"data row3 col1\" >0.843620</td>\n",
       "      <td id=\"T_035b8_row3_col2\" class=\"data row3 col2\" >0.913485</td>\n",
       "      <td id=\"T_035b8_row3_col3\" class=\"data row3 col3\" >0.755078</td>\n",
       "      <td id=\"T_035b8_row3_col4\" class=\"data row3 col4\" >0.826762</td>\n",
       "      <td id=\"T_035b8_row3_col5\" class=\"data row3 col5\" >0.842604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7e8161eb10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.read_csv(\"../data/asg3/initial_results.csv\")\n",
    "final_results.loc[-1] = [\n",
    "    \"Tuned_LightGBM\",\n",
    "    tuned_lgb_accuracy,\n",
    "    tuned_lgb_precision,\n",
    "    tuned_lgb_recall,\n",
    "    tuned_lgb_f1,\n",
    "    tuned_lgb_auc,\n",
    "]\n",
    "\n",
    "final_results.index += 1\n",
    "final_results = final_results.sort_index()\n",
    "final_results.style.background_gradient(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model = dtreeviz.model(\n",
    "    tuned_lgb,\n",
    "    tree_index=1,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    feature_names=[\"AWEI\", \"NIR\", \"Slope\", \"Elevation\"],\n",
    "    target_name=\"Flooded\",\n",
    "    class_names=[\"Non-water\", \"Flooded\"],\n",
    ")\n",
    "viz_model.view(x=X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"SR_B1\", \"SR_B2\", \"SR_B4\", \"SR_B5\", \"SR_B7\", \"z\", \"slope\", \"flooded\"]\n",
    "\n",
    "roi_geo_path = Path(\"../data/asg3/roi_geo.npy\")\n",
    "\n",
    "if Map.draw_last_feature:\n",
    "    geometry = Map.draw_last_feature.geometry()\n",
    "    bounds = geemap.ee_to_bbox(geometry)\n",
    "    np.save(roi_geo_path, bounds)\n",
    "    reduced_target_image = target_image.reduceResolution(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        \"../data/asg3/roi\",\n",
    "        geemap.ee_to_numpy(\n",
    "            reduced_target_image,\n",
    "            region=geometry,\n",
    "            scale=250,\n",
    "            bands=bands,\n",
    "        ),\n",
    "    )\n",
    "    Map.remove_drawn_features()\n",
    "else:\n",
    "    if roi_geo_path.exists():\n",
    "        bounds = np.load(roi_geo_path).tolist()\n",
    "        roi_geo = ee.Geometry.Rectangle(coords=bounds)\n",
    "        Map.centerObject(roi_geo, zoom=10)\n",
    "        roi_geo = ee.FeatureCollection(roi_geo).style(\n",
    "            fillColor=\"#3181cc33\", color=\"red\", width=1\n",
    "        )\n",
    "        Map.addLayer(roi_geo, {}, \"ROI Geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: np.ndarray = np.load(\"../data/asg3/roi.npy\")\n",
    "rows, cols, bands_len = data.shape\n",
    "\n",
    "array_2d = data.reshape(-1, bands_len)\n",
    "coordinates = [(row, col) for row in range(rows) for col in range(cols)]\n",
    "data_with_coords = [\n",
    "    {\"x\": x, \"y\": y, **{bands[i]: array_2d[idx, i] for i in range(bands_len)}}\n",
    "    for idx, (x, y) in enumerate(coordinates)\n",
    "]\n",
    "\n",
    "features = {\n",
    "    \"SR_B1\": \"Blue\",\n",
    "    \"SR_B2\": \"Green\",\n",
    "    \"SR_B4\": \"NIR\",\n",
    "    \"SR_B5\": \"SWIR_1\",\n",
    "    \"SR_B7\": \"SWIR_2\",\n",
    "    \"slope\": \"Slope\",\n",
    "    \"z\": \"Elevation\",\n",
    "}\n",
    "\n",
    "df_target_image = pd.DataFrame(data_with_coords).rename(columns=features)\n",
    "x = df_target_image[features.values()]\n",
    "y = df_target_image[\"flooded\"]\n",
    "x[\"AWEI\"] = (\n",
    "    x[\"Blue\"] + 2.5 * x[\"Green\"] - 1.5 * (x[\"NIR\"] + x[\"SWIR_1\"]) - 0.25 * x[\"SWIR_2\"]\n",
    ")\n",
    "\n",
    "y_pred = tuned_lgb.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
